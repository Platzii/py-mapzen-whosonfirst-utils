#!/usr/bin/env python

import sys
import logging
import os.path
import csv
import pprint
import geojson

import requests
import StringIO
import boto.s3.connection
import boto.s3.key

if __name__ == '__main__':

    import optparse
    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-s', '--source', dest='source', action='store', default='fs', help='Where to read files from (default is "fs")')
    opt_parser.add_option('-p', '--prefix', dest='prefix', action='store', default=None, help='Prefix for paths in CSV file (optional)')
    opt_parser.add_option('-m', '--max', dest='max', action='store', default=None, help='The maximum number of records in asingle GeoJSON file')
    opt_parser.add_option('-l', '--slim', dest='slim', action='store_true', default=False, help='Limit property export to subset (roughly those in the CSV file), reduce file size.')
    opt_parser.add_option('-k', '--slim-keys', dest='keys', action='store', default=None, help='Ordered list of keys (properties) that are exported in slim mode.')
    opt_parser.add_option('-t', '--slim-placetype', dest='placetype', action='store', default=None, help='Adjust canned list of keys in slim mode.')

    opt_parser.add_option('-c', '--csv', dest='csv', action='store', default=None, help='CSV file to read')
    opt_parser.add_option('-o', '--out', dest='out', action='store', default=None, help='Where to write feature collection (default is STDOUT)')

    opt_parser.add_option('-v', '--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')

    options, args = opt_parser.parse_args()

    if options.verbose:    
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)


    first = True
    counter = 1
    page = 1
    max_records = 0

    if options.max:
        max_records = int(options.max)
        max_records = max(0, max_records)

    logging.debug("max records per geojson file: %s" % max_records)        

    
    slim_keys = ['name','id','placetype','parent_id','country_id','region_id','locality_id','wof_country','lbl_latitude','lbl_longitude','path']
    #slim_keys = ['name','id','placetype','parent_id','country_id','region_id','locality_id','wof_country','iso_country','lbl_latitude','lbl_longitude','inception','cessation','deprecated','supersedes','superseded_by','lastmodified','source','path']

    if options.keys:
        slim_keys = options.keys.split(',')

    if options.placetype == 'neighbourhood':
        slim_keys.extend( ['is_funky','is_hard_boundary','is_landuse_aoi','is_official','max_zoom','min_zoom','tier_locality'] )

    if options.slim:
        logging.debug("slim properties export mode")
        logging.debug("\t%s" % slim_keys)

    out = None

    path = os.path.abspath(options.csv)
    fh = open(path, 'r')

    if max_records:
        lines = 0

        for ln in fh.readlines():
            lines += 1
            
            if lines == (max_records + 1):
                break

        if lines <= max_records:
            max_records = 0

        fh.seek(0)

    reader = csv.DictReader(fh)

    for row in reader:

        path = row['path']

        if options.prefix:
            path = os.path.join(options.prefix, path)

        logging.debug("fetching %s, with %s" % (path, options.source))

        fdata = None

        if options.source == 's3':
            
            try:
                rsp = requests.get(path)
            except Exception, e:
                logging.error("failed to retrieve %s, because %s" % (path, e))
                continue

            code = rsp.status_code

            if code != 200:
                logging.error("%s returned an unexpected status code: %s" (path, code))
                continue

            fdata = StringIO.StringIO()
            fdata.write(rsp.content)
            fdata.seek(0)

        else:

            if not os.path.exists(path):
                logging.error("%s does not exist, skipping" % path)
                continue

            fdata = open(path, 'r')

        try:
            geojson.load(fdata)
            fdata.seek(0)
        except Exception, e:
            logging.error("failed to parse %s, because %s" % (path, e))
            raise Exception, "SAD FACE"

        if not out:

            if options.out:

                outpath = options.out
                outpath = os.path.abspath(outpath)
                
                if max_records:

                    root = os.path.dirname(outpath)
                    fname = os.path.basename(outpath)
                    fname, ext = os.path.splitext(fname)
                    ext = ext.lstrip(".")

                    fname = "%s-%s.%s" % (fname, page, ext)
                    outpath = os.path.join(root, fname)

                logging.debug("write geojson to %s" % outpath)

                out = open(outpath, 'w')
            else:
                out = sys.stdout

            out.write("""{"type": "FeatureCollection", "features": [""")

        if first == True:
            first = False
        else:
            out.write(",")

        if options.slim:
            record = fdata.read()
            # TODO: reconstruct properties to match ordered whitelist
            out.write(record)
        else:
            out.write(fdata.read())

        counter += 1

        if counter == max_records:

            logging.debug("reached max limit for records")

            out.write("""]}""")
            out.close()
            out = None

            counter = 0
            first = True
            page += 1

    if out:
        out.write("""]}""")
        out.close()
