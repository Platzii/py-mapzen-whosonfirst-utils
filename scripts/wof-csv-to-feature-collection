#!/usr/bin/env python

import sys
import logging
import os.path
import csv
import pprint
import geojson

import requests
import StringIO
import boto.s3.connection
import boto.s3.key

if __name__ == '__main__':

    import optparse
    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-s', '--source', dest='source', action='store', default='fs', help='Where to read files from (default is "fs")')
    opt_parser.add_option('-p', '--prefix', dest='prefix', action='store', default=None, help='Prefix for paths in CSV file (optional)')
    opt_parser.add_option('-m', '--max', dest='max', action='store', default=None, help='The maximum number of records in asingle GeoJSON file')
    opt_parser.add_option('-l', '--slim', dest='slim', action='store_true', default=False, help='Limit property export to subset (roughly those in the CSV file), reduce file size.')
    opt_parser.add_option('-k', '--slim-keys', dest='keys', action='store', default=None, help='Ordered list of keys (properties) that are exported in slim mode.')
    opt_parser.add_option('-e', '--slim-template', dest='keys_template', action='store', default=None, help='Trim key names to fit Esri Shapefile format 8 char length limit.')
    opt_parser.add_option('-t', '--slim-placetype', dest='placetype', action='store', default=None, help='Add additional neighbourhood keys.')

    opt_parser.add_option('-c', '--csv', dest='csv', action='store', default=None, help='CSV file to read')
    opt_parser.add_option('-o', '--out', dest='out', action='store', default=None, help='Where to write feature collection (default is STDOUT)')

    opt_parser.add_option('-v', '--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')

    options, args = opt_parser.parse_args()

    if options.verbose:    
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)


    first = True
    counter = 1
    page = 1
    max_records = 0

    if options.max:
        max_records = int(options.max)
        max_records = max(0, max_records)

    logging.debug("max records per geojson file: %s" % max_records)        

    wof_slim_key_lookup = { 
        'name':'wof:name',
        'id':'wof:id',
        'placetype':'wof:placetype',
        'placetype':'wof:placetype',
        'parent_id':'wof:parent_id',
        'parent':'wof:parent_id',
        'country_id':'wof:hierarchy[0]["country_id"]',
        'country':'wof:hierarchy[0]["country_id"]',
        'region_id':'wof:hierarchy[0]["region_id"]',
        'region':'wof:hierarchy[0]["region_id"]',
        'locality_id':'wof:hierarchy[0]["locality_id"]',
        'locality':'wof:hierarchy[0]["locality_id"]',
        'wof_country':'wof:country',
        'wof_a3':'wof:country',
        'iso_country':'iso:country',
        'iso_a3':'iso:country',
        'lbl_latitude':'lbl:latitude',
        'lbl_lat':'lbl:latitude',
        'lbl_longitude':'lbl:longitude',
        'lbl_long':'lbl:longitude',
        'inception':'edtf:inception',
        'incept':'edtf:inception',
        'cessation':'edtf:cessation',
        'cessat':'edtf:cessation',
        'deprecated':'edtf:deprecated',
        'deprec':'edtf:deprecated',
        'supersedes':'wof:supersedes[0]',
        'super':'wof:supersedes[0]',
        'superseded_by':'wof:superseded_by[0]',
        'super_by':'wof:superseded_by[0]',
        'lastmodified':'wof:lastmodified',
        'lastmod':'wof:lastmodified',
        'source':'src:geom',
        'is_funky':'mz:is_funky',
        'is_hard_boundary':'mz:is_hard_boundary',
        'is_hard':'mz:is_hard_boundary',
        'is_landuse_aoi':'mz:is_landuse_aoi',
        'is_aoi':'mz:is_landuse_aoi',
        'is_official':'mz:is_official',
        'is_offic':'mz:is_official',
        'max_zoom':'mz:max_zoom',
        'min_zoom':'mz:min_zoom',
        'tier_locality':'mz:tier_locality',
        'tier_local':'mz:tier_locality',
        'address':'sg:address',
        'city':'sg:city',
        'cl_cat':'sg:classifiers:category',
        'cl_subcat':'sg:classifiers:subcategory',
        'cl_type':'sg:classifiers:type',
        'owner':'sg:owner',
        'phone':'sg:phone',
        'postcode':'sg:postcode',
        'province':'sg:province',
        'tags':'sg:tags'
    }
    
    slim_keys = []
    
    if options.keys:
        slim_keys = options.keys.split(',')
    else:
        if options.keys_template:
            if options.keys_template == 'shapefile':
                slim_keys = ['name','id','placetype','parent','country','region','locality','wof_a3','lbl_lat','lbl_long']
            elif options.keys_template == 'more':
                slim_keys = ['name','id','placetype','parent_id','country_id','region_id','locality_id','wof_country','iso_country','lbl_latitude','lbl_longitude','inception','cessation','deprecated','supersedes','superseded_by','lastmodified','source']
        else:
            slim_keys = ['name','id','placetype','parent_id','country_id','region_id','locality_id','wof_country','lbl_latitude','lbl_longitude']
        
        if options.placetype == 'neighbourhood':
            if options.keys_template == 'shapefile':
                slim_keys.extend( ['is_funky','is_hard','is_aoi','is_offic','max_zoom','min_zoom','tier_local'] )
            else:
                slim_keys.extend( ['is_funky','is_hard_boundary','is_landuse_aoi','is_official','max_zoom','min_zoom','tier_locality'] )

        if options.placetype == 'venue':
            if options.keys_template == 'shapefile':
                slim_keys.extend( ['address', 'city', 'cl_cat', 'cl_subcat', 'cl_type', 'owner', 'phone', 'postcode', 'province', 'tags'] )
            else:
                slim_keys.extend( ['address', 'city', 'classifiers_cat', 'classifiers_subcat', 'classifiers_type', 'owner', 'phone', 'postcode', 'province', 'tags'] )

    if options.slim:
        logging.debug("slim properties export mode")
        logging.debug("\t%s" % slim_keys)

    out = None

    path = os.path.abspath(options.csv)
    fh = open(path, 'r')

    if max_records:
        lines = 0

        for ln in fh.readlines():
            lines += 1
            
            if lines == (max_records + 1):
                break

        if lines <= max_records:
            max_records = 0

        fh.seek(0)

    reader = csv.DictReader(fh)

    for row in reader:

        # add logic here for concordance files that only have wof:id for
        # dealing with venues which only have concordance CSVs
        path = row['path']

        if options.prefix:
            path = os.path.join(options.prefix, path)

        logging.debug("fetching %s, with %s" % (path, options.source))

        fdata = None

        if options.source == 's3':
            
            try:
                rsp = requests.get(path)
            except Exception, e:
                logging.error("failed to retrieve %s, because %s" % (path, e))
                continue

            code = rsp.status_code

            if code != 200:
                logging.error("%s returned an unexpected status code: %s" (path, code))
                continue

            fdata = StringIO.StringIO()
            fdata.write(rsp.content)
            fdata.seek(0)

        else:

            if not os.path.exists(path):
                logging.error("%s does not exist, skipping" % path)
                continue

            fdata = open(path, 'r')

        try:
            geojson.load(fdata)
            fdata.seek(0)
        except Exception, e:
            logging.error("failed to parse %s, because %s" % (path, e))
            raise Exception, "SAD FACE"

        if not out:

            if options.out:

                outpath = options.out
                outpath = os.path.abspath(outpath)
                
                if max_records:

                    root = os.path.dirname(outpath)
                    fname = os.path.basename(outpath)
                    fname, ext = os.path.splitext(fname)
                    ext = ext.lstrip(".")

                    fname = "%s-%s.%s" % (fname, page, ext)
                    outpath = os.path.join(root, fname)

                logging.debug("write geojson to %s" % outpath)

                out = open(outpath, 'w')
            else:
                out = sys.stdout

            out.write("""{"type": "FeatureCollection", "features": [""")

        if first == True:
            first = False
        else:
            out.write(",")

        if options.slim:
            data = geojson.loads(fdata.read())
            props = data['properties']
            #print data # props is an object
            fresh_props = {}
            for key in slim_keys:
                try:
                    # if there are nested props, it only gets the first one, see wof_slim_key_lookup logic above
                    fresh_props.update( { key: props[ wof_slim_key_lookup[key] ] } )
                except:
                    logging.debug("\tmissing key: %s for %s" % (key, wof_slim_key_lookup[key]))
                    fresh_props.update( { key: -1 } )
            #print fresh_props
            # this won't be an ordered list, sadly
            data['properties'] = fresh_props
            #print data
            out.write(geojson.dumps(data))
        else:
            out.write(fdata.read())

        counter += 1

        if counter == max_records:

            logging.debug("reached max limit for records")

            out.write("""]}""")
            out.close()
            out = None

            counter = 0
            first = True
            page += 1

    if out:
        out.write("""]}""")
        out.close()
