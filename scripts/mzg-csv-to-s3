#!/usr/bin/env python

import sys
import logging
import os.path
import csv
import pprint
import geojson
import time

import boto.s3.connection
import boto.s3.key

if __name__ == '__main__':

    import optparse
    import ConfigParser

    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-s', '--source', dest='source', action='store', default=None, help='Where to read files from')
    opt_parser.add_option('-a', '--abspath', dest='abspath', action='store_true', default=False, help='CSV file uses absolute paths (default is false)')
    opt_parser.add_option('-c', '--csv', dest='csv', action='store', default=None, help='CSV file to read')

    opt_parser.add_option('-m', '--meta', dest='meta', action='store_true', default=False, help='Store the CSV file in the meta directory (default is false)')

    opt_parser.add_option('-b', '--bucket', dest='bucket', action='store', default=None, help='The S3 bucket for where to put files')
    opt_parser.add_option('--config', dest='config', action='store', default=None, help='Config file containing S3 credential')

    opt_parser.add_option('--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')
    opt_parser.add_option('--dry-run', dest='dryrun', action='store_true', default=False, help='Run in "dry-run" mode')

    options, args = opt_parser.parse_args()

    if options.verbose:	
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    cfg = ConfigParser.ConfigParser()
    cfg.read(options.config)

    key = cfg.get('aws', 'access_key')
    secret = cfg.get('aws', 'access_secret')

    # https://stackoverflow.com/questions/27652318/cant-connect-to-s3-buckets-with-periods-in-their-name-when-using-boto-on-herok
    # grrrrrnnnnnn.... (20150626/thisisaaronland)

    fmt = boto.s3.connection.OrdinaryCallingFormat()

    conn = boto.s3.connection.S3Connection(key, secret, calling_format=fmt)
    bucket = conn.get_bucket(options.bucket)

    if not bucket:
        logging.error("Unknown bucket")
        sys.exit()

    path = os.path.abspath(options.csv)
    fh = open(path, 'r')

    reader = csv.DictReader(fh)

    for row in reader:

        path = row['path']
        abspath = path

        if not options.abspath:
            abspath = os.path.join(options.source, path)

        if not os.path.exists(abspath):
            logging.error("%s does not exist, skipping" % abspath)
            continue

        if bucket.get_key(path):
            logging.info("a key named %s already exits, skipping" % path)
            continue

        f = open(abspath, 'r')
        data = geojson.load(f)

        props = data['properties']
        lastmod = props.get('mz:lastmodified', None)

        logging.info("Creating %s (from %s)" % (path, abspath))
        
        if options.dryrun:
            logging.info("dry-run mode enabled, just kidding")
            continue

        k = boto.s3.key.Key(bucket)
        k.key = path

        if lastmod:
            k.set_metadata('lastmodified', lastmod)

        k.set_contents_from_filename(abspath)
        k.set_acl('public-read')

    logging.info("All done, storing the contents of the CSV file")

    if options.meta:

        fname = os.path.basename(options.csv)
        path = "meta/%s" % fname

        logging.info("Storing the CSV file in %s" % path)

        if options.dryrun:
            logging.info("dry-run mode enabled, just kidding")
        else:

            try:
                k = boto.s3.key.Key(bucket)
                k.key = path            
                k.set_contents_from_filename(options.csv)
                
                try:
                    k.set_acl('public-read')
                except Exception, e:
                    logging.warning("Failed to set ACL because %s" % e)
                    time.sleep(1)
                    
                    k.set_acl('public-read')

            except Exception, e:
                logging.error("some part of storing %s failed, because %s" % (path, e))
