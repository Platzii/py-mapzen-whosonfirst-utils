#!/usr/bin/env python

import sys
import logging
import os.path
import csv
import pprint
import geojson
import time
import shutil
import hashlib

import mapzen.whosonfirst.utils
import mapzen.whosonfirst.placetypes

def hash_file(path):
    fh = open(path, 'r')
    return hash_filehandle(fh)

def hash_filehandle(fh):
    fh.seek(0)
    hash = hashlib.md5(fh.read()).hexdigest()
    return hash

if __name__ == '__main__':

    import optparse
    opt_parser = optparse.OptionParser()

    opt_parser.add_option('-s', '--source', dest='source', action='store', default=None, help='Directory to read files from')
    opt_parser.add_option('-p', '--placetypes', dest='placetypes', action='store', default=None, help='')
    opt_parser.add_option('-r', '--roles', dest='roles', action='store', default=None, help='')
    opt_parser.add_option('-c', '--csv', dest='csv', action='store', default=None, help='Directory to write concordances to (default is STDOUT)')
    opt_parser.add_option('-l', '--latest', dest='latest', action='store_true', default=False, help='Copy <PLACETYPE>-<YMD>.csv to <PLACETYPE>-latest.csv (default is False)')

    opt_parser.add_option('-v', '--verbose', dest='verbose', action='store_true', default=False, help='Be chatty (default is false)')
    options, args = opt_parser.parse_args()

    if options.verbose:	
        logging.basicConfig(level=logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)

    #

    defaults = {
        'id': 0,
        'parent_id': -1,
        'name': '',
        'fullname': '',
        'source': '',
        'path' : '',
        'lastmodified': 0,
        'iso': '',
        'bbox': '',
        'file_hash': '',
        'geom_hash': '',
        'geom_latitude': 0,
        'geom_longitude': 0,
        'lbl_latitude': 0,
        'lbl_longitude': 0,
        'supersedes': '',
        'superseded_by': '',
        }

    fn = defaults.keys()
    fn.sort()

    #

    placetypes = []

    if options.placetypes:

        for pt in options.placetypes.split(","):
            pt = pt.strip()

            if not mapzen.whosonfirst.placetypes.is_valid_placetype(pt):
                logging.error("Invalid placetype (%s)" % pt)
                sys.exit()

        placetypes.append(pt)

    elif options.roles:

        roles = []

        for rl in options.roles.split(","):

            rl = rl.strip()

            if not mapzen.whosonfirst.placetypes.is_valid_role(rl):
                logging.error("Invalid role (%s)" % (rl))
                sys.exit()

            roles.append(rl)

        placetypes = mapzen.whosonfirst.placetypes.with_roles(roles)        

    else:

        placetypes = mapzen.whosonfirst.placetypes.with_roles(('common', 'common_optional', 'optional'))

    #

    handles = {}
    writers = {}
    paths = {}
    preexisting = []

    # first create file handles and paths for each placetype

    for pt in placetypes:

        if not options.csv:
            handles[pt] = sys.stdout
            paths[pt] = None
            continue

        root = os.path.abspath(options.csv)

        now = time.gmtime()
        ymd = time.strftime("%Y%m%d", now)

        fname = "wof-%s-%s.csv" % (pt, ymd)
        outpath = os.path.join(root, fname)

        # Are we writing this file for the first time? This becomes
        # relevant if/when we are trying to clean up '-latest' files
        # below (20151110/thisisaaronland)

        if os.path.exists(outpath):
            preexisting.append(outpath)

        outfh = open(outpath, 'w')

        handles[pt] = outfh
        paths[pt] = outpath
    
    # now create a CSV writer for each placetype

    for pt, fh in handles.items():

        writer = csv.DictWriter(fh, fieldnames=fn)
        writer.writeheader()
        writers[pt] = writer

    # start crawling...

    source = os.path.abspath(options.source)
    crawl = mapzen.whosonfirst.utils.crawl(source)

    for path in crawl:

        try:
            fh = open(path, 'r')
            feature = geojson.load(fh)
        except Exception, e:
            logging.error("failed to load %s, because %s" % (path, e))
            continue

        props = feature['properties']
        placetype = props.get('wof:placetype', None)

        if not placetype:
            logging.warning("%s is missing an wof:placetype property" % path)
            continue

        if not writers.get(placetype, None):
            logging.debug("%s is a %s, so skipping" % (path, placetype))
            continue

        out = defaults

        hash = hash_filehandle(fh)
        out['file_hash'] = hash

        wofid = props.get('wof:id', None)

        if wofid == None:
            logging.warning("%s is missing an wof:id property, using filename" % path)
            fname = os.path.basename(path)
            wofid = fname.replace(".geojson", "")
            
        out['id'] = wofid

        out['parent_id'] = props.get('wof:parent_id', -1)
        
        name = props.get('wof:name', None)
        
        if not name:
            name = props.get('name', None)
            
        if not name:
            name = ""
            
        name = name.encode('utf8')
        out['name'] = name

        source = None

        for k in ('src:geom', 'wof:source', 'wof:datasource'):

            if props.get(k):
                source = props[k]
                break

        if not source:
            logging.warning("%s is missing a source property" % path)
            source = ""

        out['source'] = source
        
        path = path.replace(options.source, "")
        path = path.lstrip("/")
            
        out['path'] = path

        bbox = feature.get('bbox', None)
        
        if bbox:
            bbox = map(str, bbox)
            bbox = ",".join(bbox)
            out['bbox'] = bbox

        supersedes = props.get('wof:supersedes', [])
        superseded_by = props.get('wof:superseded_by', [])
        out['supersedes'] = ",".join(map(str, supersedes))
        out['superseded_by'] = ",".join(map(str, superseded_by))
        
        out['iso'] = props.get('iso:country', '')
        out['lastmodified'] = props.get('wof:lastmodified', 0)
        out['geom_hash'] = props.get('wof:geomhash', '')

        out['geom_latitude'] = props.get('geom:latitude', 0)
        out['geom_longitude'] = props.get('geom:longitude', 0)
        out['lbl_latitude'] = props.get('lbl:latitude', 0)
        out['lbl_longitude'] = props.get('lbl:longitude', 0)

        writer = writers[placetype]
        writer.writerow(out)

    for ignore, fh in handles.items():
        fh.close()

    if options.latest:

        for pt, path in paths.items():

            root = os.path.abspath(options.csv)
            fname = "wof-%s-latest.csv" % pt
            latest_path = os.path.join(root, fname)

            is_new = True

            # https://github.com/whosonfirst/py-mapzen-whosonfirst-utils/issues/3

            if os.path.exists(latest_path):

                ymd_hash = hash_file(path)
                latest_hash = hash_file(latest_path)

                if ymd_hash == latest_hash:
                    logging.info("%s already exists and it is the same as %s" % (latest_path, path))
                    is_new = False

            # shiny and chrome!

            if is_new:
                logging.info("copy %s to %s" % (path, latest_path))
                shutil.copy(path, latest_path)

            # recycle all the bytes

            elif not path in preexisting:
                logging.info("removing %s because it is redundant" % path)
                os.unlink(path)

            # basically a no-op but it's too late to do anything about it

            else:
                logging.debug("ALL OF THIS HAS HAPPENED BEFORE")
                pass

    sys.exit()
